{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Dataset\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "L = 6 \n",
    "df = pd.read_csv(\"music.csv\")\n",
    "#labels = np.array(df.columns.values.tolist())[0:L]\n",
    "XY = df.values\n",
    "N,n_columns = XY.shape\n",
    "D = n_columns - L\n",
    "X = XY[:,L:n_columns]\n",
    "Y = XY[:,0:L]\n",
    "Y = XY[:,0:L].astype(int).tolist()\n",
    "X = XY[:,L:].astype(float).tolist()\n",
    "N_test = 30\n",
    "N_train = N-N_test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=N_test, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design the model\n",
    "\n",
    "class multilabel_classifier(nn.Module):\n",
    "\n",
    "    def __init__(self, D, L, H=10):\n",
    "        '''\n",
    "            Setup a network Module.\n",
    "            \n",
    "            Args:\n",
    "                D (int) number of input nodes\n",
    "                H (int) number of hidden nodes\n",
    "                L (int) number of output nodes\n",
    "        '''\n",
    "        super(multilabel_classifier, self).__init__()\n",
    "\n",
    "        L_1 = int(L/2)\n",
    "        L_2 = L - L_1\n",
    "        # TODO \n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "            Defines the forward pass of the network. \n",
    "            \n",
    "            Args:\n",
    "                x : Tensor of input data\n",
    "                \n",
    "            Returns:\n",
    "                y : Tensor of output data\n",
    "        '''\n",
    "        # TODO \n",
    "        return y\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = multilabel_classifier(D,L)\n",
    "\n",
    "# Set up the loss\n",
    "optimizer = optim.Adam(h.parameters(),0.001)\n",
    "\n",
    "# TODO, assign/define my_loss = ... \n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# Fit the Model\n",
    "n_epochs = 100\n",
    "for t in range(n_epochs):\n",
    "    losses = []\n",
    "    for i in range(N_train):\n",
    "        h.train()\n",
    "        x_variable = torch.FloatTensor(X_train[i]).view(1, -1)\n",
    "        y_variable = torch.FloatTensor(Y_train[i]).view(1, -1)\n",
    "        \n",
    "        output = h(x_variable)\n",
    "        \n",
    "        # N.B. This should contain vector of marginal probabilities\n",
    "        # (each element between 0 and 1 -- it does not need to sum to unity!)\n",
    "        p_y = torch.Tensor.numpy(output.detach())\n",
    "        \n",
    "        loss = my_loss(output, y_variable)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.data.mean())\n",
    "    print('[%d/%d] Loss: %.3f' % (t+1, n_epochs, np.mean(losses)))\n",
    "\n",
    "# Visualize\n",
    "x = torch.randn(1,D)\n",
    "y = h(x)\n",
    "make_dot(y.mean(), params=dict(h.named_parameters()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model on test data and compute my_loss on test data\n",
    "preds = [] \n",
    "losses_t = []\n",
    "with torch.no_grad():\n",
    "   for i in range(N_test):\n",
    "        \n",
    "        x_t_variable = torch.FloatTensor(X_test[i]).view(1, -1)\n",
    "        y_t_variable = torch.FloatTensor(Y_test[i]).view(1, -1)\n",
    "        \n",
    "        y_hat = h(x_t_variable)\n",
    "        preds.append(y_hat)\n",
    "        loss = my_loss(y_hat, y_t_variable)\n",
    "        losses_t.append(loss.data.mean())\n",
    "   print('my_loss: %.3f' % (np.mean(losses_t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Hamming and 0/1 losses\n",
    "\n",
    "# TODO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
